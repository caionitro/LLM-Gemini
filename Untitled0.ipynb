{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsnBjGmD+xc2Rg2AKebnHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caionitro/LLM-Gemini/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epoR8c7G3mYS",
        "outputId": "57882d45-79d8-4f5b-a7b3-f1d970f3f5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.8/677.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY='AIzaSyBo8qiSKua_FqFKcpiu_vHMiBClOEMK4ec'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "xrpH9fFE3qKO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "vldgZVAI3sRp",
        "outputId": "5e9eca09-8214-47f9-9bb4-44401126f37d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5\n",
        "}"
      ],
      "metadata": {
        "id": "5F_4Lmy98Hwj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "}"
      ],
      "metadata": {
        "id": "9ESl3Z7G8SBM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\", generation_config=generation_config, safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "wn4ULXQd9YLW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos aprender conteudo sobre IA. Me dê sugestões.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "3mcyBxCp-FVo",
        "outputId": "ea40e4b8-bb46-4708-c400-c5515b1c9e4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Conceitos Fundamentais**\n",
            "\n",
            "* Definição de Inteligência Artificial (IA)\n",
            "* Tipos de IA (estreita, geral, superinteligente)\n",
            "* Aprendizado de Máquina (ML) vs. Aprendizado Profundo (DL)\n",
            "* Redes Neurais e Processamento de Linguagem Natural (PNL)\n",
            "\n",
            "**Aplicações da IA**\n",
            "\n",
            "* Reconhecimento de imagem e vídeo\n",
            "* Processamento de linguagem natural (chatbots, tradução)\n",
            "* Veículos autônomos e robótica\n",
            "* Cuidados de saúde e diagnósticos médicos\n",
            "* Finanças e previsão de mercado\n",
            "\n",
            "**Ética e Implicações Sociais da IA**\n",
            "\n",
            "* Preconceito e discriminação em algoritmos\n",
            "* Perda de empregos e automação\n",
            "* Regulamentação e governança da IA\n",
            "* Implicações éticas para o uso da IA em áreas como vigilância e guerra\n",
            "\n",
            "**Técnicas e Algoritmos de IA**\n",
            "\n",
            "* Aprendizado Supervisionado e Não Supervisionado\n",
            "* Árvores de Decisão e Florestas Aleatórias\n",
            "* Regressão Logística e Máquinas de Vetores de Suporte (SVM)\n",
            "* Redes Neurais Convolucionais (CNNs) e Redes Neurais Recorrentes (RNNs)\n",
            "\n",
            "**Ferramentas e Bibliotecas de IA**\n",
            "\n",
            "* Python e bibliotecas como NumPy, Pandas e Scikit-learn\n",
            "* Tensorflow e PyTorch para aprendizado profundo\n",
            "* Plataformas de IA em nuvem (AWS, Azure, GCP)\n",
            "\n",
            "**Recursos Adicionais**\n",
            "\n",
            "* Cursos online (Coursera, edX, Udemy)\n",
            "* Livros e artigos acadêmicos\n",
            "* Conferências e workshops da indústria\n",
            "* Comunidades online e fóruns de discussão\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "gwGwHYMv-uIi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print(\"Resposta:\", response.text, \"\\n\")\n",
        "  prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "4TI1Uo91_CP-",
        "outputId": "51625c0c-936e-407a-8131-7131eb3ba75e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt: Qual é a capital do Japão?\n",
            "Resposta: Tóquio \n",
            "\n",
            "Esperando prompt: Qual é a comida típica desse País?\n",
            "Resposta: Sushi \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PmOla0LAAMwS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}